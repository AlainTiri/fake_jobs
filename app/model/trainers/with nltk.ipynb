{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f54eeb",
   "metadata": {},
   "source": [
    "# Trainer for fakes jobs detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc32c57",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c962730",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pandas scikit-learn nltk\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9b3dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alain\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = stopwords.words('english')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d367356",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfe932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandataset(df):\n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"&amp;\", \"&\", regex=False)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"\\xa0\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"!\", \"! \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"?\", \"? \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\":\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"...\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"  +\", \" \", regex=True)\n",
    "    df[\"description\"] = df['description'].str.replace(\"([a-z]{2,})([A-Z])\", \"\\g<1> \\g<2>\", regex=True)\n",
    "    df[\"description\"] = df['description'].str.replace(\"([a-z\\.]{2,})([A-Z])\", \"\\g<1> \\g<2>\", regex=True)\n",
    "    df[\"description\"] = df['description'].str.lower()\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess(text):\n",
    "    if type(text) is float:\n",
    "        return \"\"\n",
    "    text = text.replace(\"&amp;\", \"&\")\n",
    "    text = text.replace(\"!\", \"! \")\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    text = text.replace(\"?\", \"? \")\n",
    "    text = text.replace(\":\", \" \")\n",
    "    text = text.replace(\"...\", \" \")\n",
    "    text = text.replace(\"  +\", \" \")\n",
    "    text = re.sub( r\"([a-z\\.]{2,})([A-Z])\", r\"\\g<1> \\g<2>\", text)\n",
    "    text = re.sub(r\"([a-z]{2,})([A-Z])\", r\"\\g<1> \\g<2>\", text)\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords]\n",
    " \n",
    "    clean_description = ' '.join(tokens)     \n",
    "    return clean_description\n",
    "\n",
    "def clean_data(text):\n",
    "    if type(text) is float:\n",
    "        return \"\"\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords]\n",
    " \n",
    "    clean_description = ' '.join(tokens)     \n",
    "    return clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275958c0",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929dc17",
   "metadata": {},
   "source": [
    "### Function reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47510666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(df, model, df_fraud, df_true, frac: float):\n",
    "    \"\"\"\n",
    "    :var df: pd.DataFrame with all datas\n",
    "    :var model: model of ML to use\n",
    "    :var df_fraud and df_true: df splitted with true and false jobs separated\n",
    "    :var frac: % of df_true to use for training\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the df_true to re balance the dataset\n",
    "    print(f\"\\nfrac = {frac}\")\n",
    "    df_true_sample = df_true.sample(frac=frac, random_state=0)\n",
    "\n",
    "    df_reshape = pd.concat([df_fraud, df_true_sample])\n",
    "    # df_reshape = df_reshape.sample(frac=1)\n",
    "    \n",
    "    # check class distribution\n",
    "    print(\"re shape\")\n",
    "    print(df_reshape['fraudulent'].value_counts(normalize = True))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features = 50000, \n",
    "        lowercase=False , \n",
    "        ngram_range=(1,3))\n",
    "    \n",
    "    X = df_reshape.description\n",
    "    y = df_reshape.fraudulent\n",
    "\n",
    "    train_X , test_X , train_y , test_y = train_test_split(X , y , test_size = 0.2 , random_state = 0)\n",
    "    \n",
    "    # Vectorizer\n",
    "    vec = vectorizer.fit(train_X)\n",
    "    \n",
    "    vec_train = vec.transform(train_X)\n",
    "    vec_train = vec_train.toarray()\n",
    "\n",
    "    vec_test = vectorizer.transform(test_X).toarray()\n",
    "\n",
    "    train_data = pd.DataFrame(vec_train , columns=vectorizer.get_feature_names())\n",
    "    test_data = pd.DataFrame(vec_test , columns= vectorizer.get_feature_names())\n",
    "\n",
    "    # Training of the model selected in input\n",
    "    model.fit(train_data, train_y)\n",
    "    predictions  = model.predict(test_data)\n",
    "\n",
    "    print(classification_report(test_y , predictions))\n",
    "    # confusion matrix\n",
    "    print(pd.crosstab(test_y, predictions), end=\"\\n\\n\")\n",
    "    \n",
    "    # return a dict with informations and the models (ML + vectorizer)\n",
    "    return {frac: {\"model\": model, \"vectorizer\": vec}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b13072",
   "metadata": {},
   "source": [
    "## Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f62b7d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': SVC(), 'vectorizer': TfidfVectorizer(lowercase=False, max_features=50000, ngram_range=(1, 3))}\n",
      "[1]\n",
      "\n",
      "frac=0.07\n",
      "re shape\n",
      "0    0.611461\n",
      "1    0.388539\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       189\n",
      "           1       0.99      0.56      0.71       129\n",
      "\n",
      "    accuracy                           0.82       318\n",
      "   macro avg       0.88      0.78      0.79       318\n",
      "weighted avg       0.86      0.82      0.80       318\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           188   1\n",
      "1            57  72\n"
     ]
    }
   ],
   "source": [
    "# Modèle sélectionné\n",
    "# frac = 12\n",
    "# vect avec 50000 features\n",
    "# SVM non fine-tuned - the defaults values are goods.\n",
    "\n",
    "mymodel = models[4][0.07]\n",
    "print(mymodel)\n",
    "\n",
    "text = [preprocess(\"IC&amp;E Technician | Bakersfield, CA Mt. PosoPrincipal Duties and Responsibilities: Calibrates, tests, maintains, troubleshoots, and installs all power plant instrumentation, control systems and electrical equipment.Performs maintenance on motor control centers, motor operated valves, generators, excitation equipment and motors.Performs preventive, predictive and corrective maintenance on equipment, coordinating work with various team members.Designs and installs new equipment and/or system modifications.Troubleshoots and performs maintenance on DC backup power equipment, process controls, programmable logic controls (PLC), and emission monitoring equipment.Uses maintenance reporting system to record time and material use, problem identified and corrected, and further action required; provides complete history of maintenance on equipment.Schedule, coordinate, work with and monitor contractors on specific tasks, as required.Follows safe working practices at all times.Identifies safety hazards and recommends solutions.Follows environmental compliance work practices.Identifies environmental non-compliance problems and assist in implementing solutions.Assists other team members and works with all departments to support generating station in achieving their performance goals.Trains other team members in the areas of instrumentation, control, and electrical systems.Performs housekeeping assignments, as directed.Conduct equipment and system tagging according to company and plant rules and regulations.Perform equipment safety inspections, as required, and record results as appropriate. Participate in small construction projects.  Read and interpret drawings, sketches, prints, and specifications, as required.Orders parts as needed to affect maintenance and repair.Performs Operations tasks on an as-needed basis and other tasks as assigned.Available within a reasonable response time for emergency call-ins and overtime, plus provide acceptable off-hour contact by phone and company pager.          Excellent Verbal and Written Communications Skills:Ability to coordinate work activities with other team members on technical subjects across job families.Ability to work weekends, holidays, and rotating shifts, as required.\")]\n",
    "vectorizer = mymodel[\"vectorizer\"]\n",
    "vec_test = vectorizer.transform(text).toarray()\n",
    "test_data = pd.DataFrame(vec_test, columns= vectorizer.get_feature_names())\n",
    "\n",
    "print(mymodel[\"model\"].predict(vec_test))\n",
    "print(\n",
    "\n",
    "\"\"\"\n",
    "frac=0.07\n",
    "re shape\n",
    "0    0.611461\n",
    "1    0.388539\n",
    "Name: fraudulent, dtype: float64\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.99      0.87       189\n",
    "           1       0.99      0.56      0.71       129\n",
    "\n",
    "    accuracy                           0.82       318\n",
    "   macro avg       0.88      0.78      0.79       318\n",
    "weighted avg       0.86      0.82      0.80       318\n",
    "\n",
    "col_0         0   1\n",
    "fraudulent         \n",
    "0           188   1\n",
    "1            57  72\"\"\")\n",
    "\n",
    "with open(\"model_svm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mymodel[\"model\"], f)\n",
    "    \n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mymodel[\"vectorizer\"], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efcb7a",
   "metadata": {},
   "source": [
    "## Others tested tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372afa0c",
   "metadata": {},
   "source": [
    "### With a sample of 12% of true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "119d731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729103\n",
      "1    0.270897\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       322\n",
      "           1       0.98      0.39      0.55       135\n",
      "\n",
      "    accuracy                           0.82       457\n",
      "   macro avg       0.89      0.69      0.72       457\n",
      "weighted avg       0.85      0.82      0.79       457\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           321   1\n",
      "1            83  52\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "# frac = [x * 0.01 for x in range(6, 14)]\n",
    "model = trainer(df, svm.SVC(), df_fraud, df_true, 0.12)\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1571bb",
   "metadata": {},
   "source": [
    "### With a loop for testing a diversity of values of df_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "59abd8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95741\n",
      "1    0.04259\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.03\n",
      "re shape\n",
      "1    0.597289\n",
      "0    0.402711\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76        84\n",
      "           1       0.81      0.89      0.85       123\n",
      "\n",
      "    accuracy                           0.82       207\n",
      "   macro avg       0.82      0.80      0.80       207\n",
      "weighted avg       0.82      0.82      0.81       207\n",
      "\n",
      "col_0        0    1\n",
      "fraudulent         \n",
      "0           59   25\n",
      "1           13  110\n",
      "\n",
      "\n",
      "frac = 0.04\n",
      "re shape\n",
      "1    0.526451\n",
      "0    0.473549\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       114\n",
      "           1       0.80      0.84      0.82       121\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.81      0.81      0.81       235\n",
      "weighted avg       0.81      0.81      0.81       235\n",
      "\n",
      "col_0        0    1\n",
      "fraudulent         \n",
      "0           89   25\n",
      "1           19  102\n",
      "\n",
      "\n",
      "frac = 0.05\n",
      "re shape\n",
      "0    0.529367\n",
      "1    0.470633\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       134\n",
      "           1       0.89      0.71      0.79       129\n",
      "\n",
      "    accuracy                           0.82       263\n",
      "   macro avg       0.83      0.82      0.81       263\n",
      "weighted avg       0.83      0.82      0.82       263\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           123  11\n",
      "1            37  92\n",
      "\n",
      "\n",
      "frac = 0.06\n",
      "re shape\n",
      "0    0.574189\n",
      "1    0.425811\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84       164\n",
      "           1       0.93      0.56      0.70       126\n",
      "\n",
      "    accuracy                           0.79       290\n",
      "   macro avg       0.84      0.77      0.77       290\n",
      "weighted avg       0.83      0.79      0.78       290\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           159   5\n",
      "1            55  71\n",
      "\n",
      "\n",
      "frac = 0.07\n",
      "re shape\n",
      "0    0.611461\n",
      "1    0.388539\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       189\n",
      "           1       0.99      0.56      0.71       129\n",
      "\n",
      "    accuracy                           0.82       318\n",
      "   macro avg       0.88      0.78      0.79       318\n",
      "weighted avg       0.86      0.82      0.80       318\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           188   1\n",
      "1            57  72\n",
      "\n",
      "\n",
      "frac = 0.08\n",
      "re shape\n",
      "0    0.642733\n",
      "1    0.357267\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       218\n",
      "           1       1.00      0.44      0.61       128\n",
      "\n",
      "    accuracy                           0.79       346\n",
      "   macro avg       0.88      0.72      0.73       346\n",
      "weighted avg       0.84      0.79      0.77       346\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           218   0\n",
      "1            72  56\n",
      "\n",
      "\n",
      "frac = 0.09\n",
      "re shape\n",
      "0    0.669169\n",
      "1    0.330831\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       241\n",
      "           1       1.00      0.39      0.57       132\n",
      "\n",
      "    accuracy                           0.79       373\n",
      "   macro avg       0.88      0.70      0.71       373\n",
      "weighted avg       0.84      0.79      0.75       373\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           241   0\n",
      "1            80  52\n",
      "\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.692116\n",
      "1    0.307884\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       263\n",
      "           1       0.98      0.39      0.56       138\n",
      "\n",
      "    accuracy                           0.79       401\n",
      "   macro avg       0.87      0.69      0.71       401\n",
      "weighted avg       0.83      0.79      0.76       401\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           262   1\n",
      "1            84  54\n",
      "\n",
      "\n",
      "frac = 0.11\n",
      "re shape\n",
      "0    0.712086\n",
      "1    0.287914\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88       296\n",
      "           1       0.98      0.39      0.56       133\n",
      "\n",
      "    accuracy                           0.81       429\n",
      "   macro avg       0.88      0.69      0.72       429\n",
      "weighted avg       0.85      0.81      0.78       429\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           295   1\n",
      "1            81  52\n",
      "\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729505\n",
      "1    0.270495\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       326\n",
      "           1       0.98      0.35      0.52       131\n",
      "\n",
      "    accuracy                           0.81       457\n",
      "   macro avg       0.89      0.67      0.70       457\n",
      "weighted avg       0.85      0.81      0.78       457\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           325   1\n",
      "1            85  46\n",
      "\n",
      "\n",
      "frac = 0.13\n",
      "re shape\n",
      "0    0.745041\n",
      "1    0.254959\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       359\n",
      "           1       0.98      0.34      0.50       125\n",
      "\n",
      "    accuracy                           0.83       484\n",
      "   macro avg       0.89      0.67      0.70       484\n",
      "weighted avg       0.85      0.83      0.79       484\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           358   1\n",
      "1            83  42\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.01 for x in range(3, 14)]\n",
    "models = [trainer(df, svm.SVC(), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4ce78df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/463563447.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mfrac\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msvm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSVC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_fraud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfrac\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/463563447.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mfrac\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msvm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSVC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_fraud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfrac\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/3653330113.py\u001B[0m in \u001B[0;36mtrainer\u001B[1;34m(df, model, df_fraud, df_true, frac)\u001B[0m\n\u001B[0;32m     15\u001B[0m         ngram_range=(1,3))\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvectorizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"vectorizer.pkl\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf_reshape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdescription\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "# By steps of 10%\n",
    "frac = [x * 0.1 for x in range(1, 10)]\n",
    "models = [trainer(df, svm.SVC(), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151c47d",
   "metadata": {},
   "source": [
    "### An example of the behavior with no deduplication of datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85e16fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17880, 2)\n",
      "(17880, 2)\n",
      "0    0.951566\n",
      "1    0.048434\n",
      "Name: fraudulent, dtype: float64\n",
      "(866, 2)\n",
      "(17014, 2)\n",
      "(1701, 2)\n",
      "0    0.662641\n",
      "1    0.337359\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       344\n",
      "           1       0.98      0.70      0.82       170\n",
      "\n",
      "    accuracy                           0.89       514\n",
      "   macro avg       0.92      0.85      0.87       514\n",
      "weighted avg       0.90      0.89      0.89       514\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           341    3\n",
      "1            51  119\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "def cleandataset(df):\n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"&amp;\", \"&\", regex=False)\n",
    "    df[\"description\"] = df[\"description\"].str.replace(\"\\xa0\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"!\", \"! \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"?\", \"? \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\":\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"...\", \" \", regex=False)\n",
    "    df[\"description\"] = df['description'].str.replace(\"  +\", \" \", regex=True)\n",
    "    df[\"description\"] = df['description'].str.replace(\"([a-z]{2,})([A-Z])\", \"\\g<1> \\g<2>\", regex=True)\n",
    "    df[\"description\"] = df['description'].str.replace(\"([a-z\\.]{2,})([A-Z])\", \"\\g<1> \\g<2>\", regex=True)\n",
    "    df[\"description\"] = df['description'].str.lower()\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "#     df.drop_duplicates(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(text):\n",
    "#     text = re.sub('[^a-zA-Z]' , ' ' , text)\n",
    "    if type(text) is float:\n",
    "        return \"\"\n",
    "    tokens = text.split() \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if not word in stopwords]  \n",
    "    clean_description = ' '.join(tokens)     \n",
    "    return clean_description\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df = cleandataset(df)\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# check class distribution\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "print(df_fraud.shape)\n",
    "\n",
    "df_true_sample = df_true.sample(frac=0.1, random_state=0)\n",
    "print(df_true.shape)\n",
    "print(df_true_sample.shape)\n",
    "\n",
    "df_reshape = pd.concat([df_fraud, df_true_sample])\n",
    "df_reshape = df_reshape.sample(frac=1)\n",
    "# check class distribution\n",
    "print(df_reshape['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features = 50000 , \n",
    "    lowercase=False , \n",
    "    ngram_range=(1,3))\n",
    "\n",
    "X = df_reshape.description\n",
    "y = df_reshape.fraudulent\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X , test_X , train_y , test_y = train_test_split(X , y , test_size = 0.2 ,random_state = 0)\n",
    "\n",
    "vec_train = vectorizer.fit_transform(train_X)\n",
    "vec_train = vec_train.toarray()\n",
    "\n",
    "vec_test = vectorizer.transform(test_X).toarray()\n",
    "\n",
    "train_data = pd.DataFrame(vec_train , columns=vectorizer.get_feature_names())\n",
    "test_data = pd.DataFrame(vec_test , columns= vectorizer.get_feature_names())\n",
    "\n",
    "from sklearn import svm\n",
    "model_svm = svm.SVC()\n",
    "\n",
    "model_svm.fit(train_data, train_y)\n",
    "predictions  = model_svm.predict(test_data)\n",
    "\n",
    "print(classification_report(test_y , predictions))\n",
    "# confusion matrix\n",
    "print(pd.crosstab(test_y, predictions))\n",
    "\n",
    "model_svm2 = model_svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efa829",
   "metadata": {},
   "source": [
    "# The diversity of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c0c24",
   "metadata": {},
   "source": [
    "I had try a lot of models before to chose one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb1212",
   "metadata": {},
   "source": [
    "## SVM\n",
    "The tuning by class_weight doesn't change the game. (Maybe others parameters ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a129443b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 1\n",
      "re shape\n",
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2764\n",
      "           1       0.93      0.40      0.56       136\n",
      "\n",
      "    accuracy                           0.97      2900\n",
      "   macro avg       0.95      0.70      0.77      2900\n",
      "weighted avg       0.97      0.97      0.97      2900\n",
      "\n",
      "col_0          0   1\n",
      "fraudulent          \n",
      "0           2760   4\n",
      "1             81  55\n",
      "\n",
      "end\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/2253680121.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[0mpickle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_svm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'model_svm.pkl'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcrosstab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.1 for x in range(0, 10)]\n",
    "model = trainer(df, svm.SVC(class_weight={1: 22}), df_fraud, df_true, 1)\n",
    "\n",
    "print(\"end\")\n",
    "\n",
    "# with open('model_svm.pkl', \"wb\") as f:\n",
    "#     pickle.dump(model, f)\n",
    "print(pd.crosstab(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ace0c4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           233   7\n",
      "1            49  57\n"
     ]
    }
   ],
   "source": [
    "with open('model_svm.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(pd.crosstab(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f54f8e",
   "metadata": {},
   "source": [
    "## Naive Bayes - MultinomailNB\n",
    "Could be usefull if we want to never have a true classed like fake, but with less trues falses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8a576c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.06\n",
      "re shape\n",
      "0    0.573691\n",
      "1    0.426309\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.80       163\n",
      "           1       0.98      0.39      0.56       128\n",
      "\n",
      "    accuracy                           0.73       291\n",
      "   macro avg       0.83      0.69      0.68       291\n",
      "weighted avg       0.81      0.73      0.70       291\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           162   1\n",
      "1            78  50\n",
      "\n",
      "\n",
      "frac = 0.07\n",
      "re shape\n",
      "0    0.610937\n",
      "1    0.389063\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.81       195\n",
      "           1       0.97      0.29      0.45       124\n",
      "\n",
      "    accuracy                           0.72       319\n",
      "   macro avg       0.83      0.64      0.63       319\n",
      "weighted avg       0.80      0.72      0.67       319\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           194   1\n",
      "1            88  36\n",
      "\n",
      "\n",
      "frac = 0.08\n",
      "re shape\n",
      "0    0.64199\n",
      "1    0.35801\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81       218\n",
      "           1       1.00      0.21      0.35       128\n",
      "\n",
      "    accuracy                           0.71       346\n",
      "   macro avg       0.84      0.61      0.58       346\n",
      "weighted avg       0.80      0.71      0.64       346\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           218   0\n",
      "1           101  27\n",
      "\n",
      "\n",
      "frac = 0.09\n",
      "re shape\n",
      "0    0.66863\n",
      "1    0.33137\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       239\n",
      "           1       1.00      0.22      0.36       135\n",
      "\n",
      "    accuracy                           0.72       374\n",
      "   macro avg       0.85      0.61      0.59       374\n",
      "weighted avg       0.80      0.72      0.66       374\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           239   0\n",
      "1           105  30\n",
      "\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83       264\n",
      "           1       0.97      0.22      0.36       138\n",
      "\n",
      "    accuracy                           0.73       402\n",
      "   macro avg       0.84      0.61      0.60       402\n",
      "weighted avg       0.80      0.73      0.67       402\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           263   1\n",
      "1           107  31\n",
      "\n",
      "\n",
      "frac = 0.11\n",
      "re shape\n",
      "0    0.711556\n",
      "1    0.288444\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84       293\n",
      "           1       0.97      0.22      0.36       137\n",
      "\n",
      "    accuracy                           0.75       430\n",
      "   macro avg       0.85      0.61      0.60       430\n",
      "weighted avg       0.81      0.75      0.69       430\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           292   1\n",
      "1           107  30\n",
      "\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729103\n",
      "1    0.270897\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85       322\n",
      "           1       0.96      0.20      0.33       135\n",
      "\n",
      "    accuracy                           0.76       457\n",
      "   macro avg       0.86      0.60      0.59       457\n",
      "weighted avg       0.81      0.76      0.70       457\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           321   1\n",
      "1           108  27\n",
      "\n",
      "\n",
      "frac = 0.13\n",
      "re shape\n",
      "0    0.744637\n",
      "1    0.255363\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88       361\n",
      "           1       1.00      0.20      0.34       124\n",
      "\n",
      "    accuracy                           0.80       485\n",
      "   macro avg       0.89      0.60      0.61       485\n",
      "weighted avg       0.84      0.80      0.74       485\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           361   0\n",
      "1            99  25\n",
      "\n",
      "\n",
      "frac = 0.14\n",
      "re shape\n",
      "0    0.758392\n",
      "1    0.241608\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       396\n",
      "           1       1.00      0.21      0.35       117\n",
      "\n",
      "    accuracy                           0.82       513\n",
      "   macro avg       0.91      0.61      0.62       513\n",
      "weighted avg       0.85      0.82      0.77       513\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           396   0\n",
      "1            92  25\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.01 for x in range(6, 15)]\n",
    "models = [trainer(df, MultinomialNB(), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7154b",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "The result was not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d6fd8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.06\n",
      "re shape\n",
      "0    0.573691\n",
      "1    0.426309\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       163\n",
      "           1       0.86      0.69      0.77       128\n",
      "\n",
      "    accuracy                           0.81       291\n",
      "   macro avg       0.83      0.80      0.81       291\n",
      "weighted avg       0.82      0.81      0.81       291\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           149  14\n",
      "1            40  88\n",
      "\n",
      "\n",
      "frac = 0.07\n",
      "re shape\n",
      "0    0.610937\n",
      "1    0.389063\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86       195\n",
      "           1       0.89      0.60      0.71       124\n",
      "\n",
      "    accuracy                           0.82       319\n",
      "   macro avg       0.84      0.78      0.79       319\n",
      "weighted avg       0.83      0.82      0.81       319\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           186   9\n",
      "1            50  74\n",
      "\n",
      "\n",
      "frac = 0.08\n",
      "re shape\n",
      "0    0.64199\n",
      "1    0.35801\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       218\n",
      "           1       0.88      0.59      0.70       128\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.84      0.77      0.79       346\n",
      "weighted avg       0.83      0.82      0.81       346\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           208  10\n",
      "1            53  75\n",
      "\n",
      "\n",
      "frac = 0.09\n",
      "re shape\n",
      "0    0.66863\n",
      "1    0.33137\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       239\n",
      "           1       0.84      0.62      0.71       135\n",
      "\n",
      "    accuracy                           0.82       374\n",
      "   macro avg       0.83      0.78      0.79       374\n",
      "weighted avg       0.82      0.82      0.81       374\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           223  16\n",
      "1            51  84\n",
      "\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       264\n",
      "           1       0.86      0.55      0.67       138\n",
      "\n",
      "    accuracy                           0.82       402\n",
      "   macro avg       0.83      0.75      0.77       402\n",
      "weighted avg       0.82      0.82      0.80       402\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           252  12\n",
      "1            62  76\n",
      "\n",
      "\n",
      "frac = 0.11\n",
      "re shape\n",
      "0    0.711556\n",
      "1    0.288444\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89       293\n",
      "           1       0.91      0.52      0.66       137\n",
      "\n",
      "    accuracy                           0.83       430\n",
      "   macro avg       0.86      0.75      0.77       430\n",
      "weighted avg       0.84      0.83      0.81       430\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           286   7\n",
      "1            66  71\n",
      "\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729103\n",
      "1    0.270897\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       322\n",
      "           1       0.92      0.50      0.65       135\n",
      "\n",
      "    accuracy                           0.84       457\n",
      "   macro avg       0.87      0.74      0.77       457\n",
      "weighted avg       0.85      0.84      0.82       457\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           316   6\n",
      "1            67  68\n",
      "\n",
      "\n",
      "frac = 0.13\n",
      "re shape\n",
      "0    0.744637\n",
      "1    0.255363\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90       361\n",
      "           1       0.86      0.45      0.59       124\n",
      "\n",
      "    accuracy                           0.84       485\n",
      "   macro avg       0.85      0.71      0.75       485\n",
      "weighted avg       0.84      0.84      0.82       485\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           352   9\n",
      "1            68  56\n",
      "\n",
      "\n",
      "frac = 0.14\n",
      "re shape\n",
      "0    0.758392\n",
      "1    0.241608\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       396\n",
      "           1       0.90      0.49      0.63       117\n",
      "\n",
      "    accuracy                           0.87       513\n",
      "   macro avg       0.89      0.74      0.78       513\n",
      "weighted avg       0.88      0.87      0.86       513\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           390   6\n",
      "1            60  57\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.01 for x in range(6, 15)]\n",
    "models = [trainer(df, RandomForestClassifier(n_estimators=20), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8c711",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier\n",
    "Similare results than svm, but less good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61f031da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.06\n",
      "re shape\n",
      "0    0.573691\n",
      "1    0.426309\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84       163\n",
      "           1       0.91      0.62      0.73       128\n",
      "\n",
      "    accuracy                           0.80       291\n",
      "   macro avg       0.83      0.78      0.79       291\n",
      "weighted avg       0.83      0.80      0.80       291\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           155   8\n",
      "1            49  79\n",
      "\n",
      "\n",
      "frac = 0.07\n",
      "re shape\n",
      "0    0.610937\n",
      "1    0.389063\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87       195\n",
      "           1       0.90      0.60      0.72       124\n",
      "\n",
      "    accuracy                           0.82       319\n",
      "   macro avg       0.85      0.78      0.79       319\n",
      "weighted avg       0.83      0.82      0.81       319\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           187   8\n",
      "1            50  74\n",
      "\n",
      "\n",
      "frac = 0.08\n",
      "re shape\n",
      "0    0.64199\n",
      "1    0.35801\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       218\n",
      "           1       0.89      0.63      0.74       128\n",
      "\n",
      "    accuracy                           0.84       346\n",
      "   macro avg       0.85      0.79      0.81       346\n",
      "weighted avg       0.84      0.84      0.83       346\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           208  10\n",
      "1            47  81\n",
      "\n",
      "\n",
      "frac = 0.09\n",
      "re shape\n",
      "0    0.66863\n",
      "1    0.33137\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88       239\n",
      "           1       0.94      0.58      0.72       135\n",
      "\n",
      "    accuracy                           0.83       374\n",
      "   macro avg       0.87      0.78      0.80       374\n",
      "weighted avg       0.85      0.83      0.82       374\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           234   5\n",
      "1            57  78\n",
      "\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       264\n",
      "           1       0.91      0.56      0.69       138\n",
      "\n",
      "    accuracy                           0.83       402\n",
      "   macro avg       0.86      0.76      0.79       402\n",
      "weighted avg       0.84      0.83      0.82       402\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           256   8\n",
      "1            61  77\n",
      "\n",
      "\n",
      "frac = 0.11\n",
      "re shape\n",
      "0    0.711556\n",
      "1    0.288444\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       293\n",
      "           1       0.94      0.56      0.70       137\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.88      0.77      0.80       430\n",
      "weighted avg       0.86      0.85      0.84       430\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           288   5\n",
      "1            60  77\n",
      "\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729103\n",
      "1    0.270897\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       322\n",
      "           1       0.89      0.50      0.64       135\n",
      "\n",
      "    accuracy                           0.84       457\n",
      "   macro avg       0.86      0.74      0.77       457\n",
      "weighted avg       0.84      0.84      0.82       457\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           314   8\n",
      "1            67  68\n",
      "\n",
      "\n",
      "frac = 0.13\n",
      "re shape\n",
      "0    0.744637\n",
      "1    0.255363\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       361\n",
      "           1       0.92      0.47      0.62       124\n",
      "\n",
      "    accuracy                           0.85       485\n",
      "   macro avg       0.88      0.73      0.76       485\n",
      "weighted avg       0.86      0.85      0.84       485\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           356   5\n",
      "1            66  58\n",
      "\n",
      "\n",
      "frac = 0.14\n",
      "re shape\n",
      "0    0.758392\n",
      "1    0.241608\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       396\n",
      "           1       0.90      0.49      0.63       117\n",
      "\n",
      "    accuracy                           0.87       513\n",
      "   macro avg       0.89      0.74      0.78       513\n",
      "weighted avg       0.88      0.87      0.86       513\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           390   6\n",
      "1            60  57\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.01 for x in range(6, 15)]\n",
    "models = [trainer(df, ExtraTreesClassifier(n_estimators=20), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28453e6f",
   "metadata": {},
   "source": [
    "## IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1855e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00       264\n",
      "           1       0.34      0.99      0.51       138\n",
      "\n",
      "    accuracy                           0.34       402\n",
      "   macro avg       0.11      0.33      0.17       402\n",
      "weighted avg       0.12      0.34      0.18       402\n",
      "\n",
      "col_0       -1    1\n",
      "fraudulent         \n",
      "0            3  261\n",
      "1            1  137\n",
      "\n",
      "\n",
      "frac = 0.2\n",
      "re shape\n",
      "0    0.817673\n",
      "1    0.182327\n",
      "Name: fraudulent, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00       549\n",
      "           1       0.19      1.00      0.33       130\n",
      "\n",
      "    accuracy                           0.19       679\n",
      "   macro avg       0.06      0.33      0.11       679\n",
      "weighted avg       0.04      0.19      0.06       679\n",
      "\n",
      "col_0       -1    1\n",
      "fraudulent         \n",
      "0            9  540\n",
      "1            0  130\n",
      "\n",
      "\n",
      "frac = 0.30000000000000004\n",
      "re shape\n",
      "0    0.870583\n",
      "1    0.129417\n",
      "Name: fraudulent, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00       824\n",
      "           1       0.14      1.00      0.24       133\n",
      "\n",
      "    accuracy                           0.14       957\n",
      "   macro avg       0.05      0.33      0.08       957\n",
      "weighted avg       0.02      0.14      0.03       957\n",
      "\n",
      "col_0       -1    1\n",
      "fraudulent         \n",
      "0            4  820\n",
      "1            0  133\n",
      "\n",
      "\n",
      "frac = 0.4\n",
      "re shape\n",
      "0    0.899692\n",
      "1    0.100308\n",
      "Name: fraudulent, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/3082874088.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mfrac\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIsolationForest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontamination\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m42\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_fraud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfrac\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/3082874088.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mfrac\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.1\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[0mmodels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtrainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mIsolationForest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontamination\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m42\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_fraud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfrac\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"end\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/1742650012.py\u001B[0m in \u001B[0;36mtrainer\u001B[1;34m(df, model, df_fraud, df_true, frac)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     32\u001B[0m     \u001B[0mpredictions\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    276\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_samples_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax_samples\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    277\u001B[0m         \u001B[0mmax_depth\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mceil\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlog2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 278\u001B[1;33m         super()._fit(X, y, max_samples,\n\u001B[0m\u001B[0;32m    279\u001B[0m                      \u001B[0mmax_depth\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    280\u001B[0m                      sample_weight=sample_weight)\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001B[0m\n\u001B[0;32m    368\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_seeds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mseeds\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 370\u001B[1;33m         all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001B[0m\u001B[0;32m    371\u001B[0m                                \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m             delayed(_parallel_build_estimators)(\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1043\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1045\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    860\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    863\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 779\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    780\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    781\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_parallel_build_estimators\u001B[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001B[0m\n\u001B[0;32m    109\u001B[0m                 \u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnot_indices_mask\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcurr_sample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.1 for x in range(1, 10)]\n",
    "models = [trainer(df, IsolationForest(contamination=float(0.01),random_state=42), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e90330",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier\n",
    "Well balanced results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "360c5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.95731\n",
      "1    0.04269\n",
      "Name: fraudulent, dtype: float64\n",
      "\n",
      "frac = 0.06\n",
      "re shape\n",
      "0    0.573691\n",
      "1    0.426309\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       163\n",
      "           1       0.85      0.83      0.84       128\n",
      "\n",
      "    accuracy                           0.86       291\n",
      "   macro avg       0.86      0.86      0.86       291\n",
      "weighted avg       0.86      0.86      0.86       291\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           145   18\n",
      "1            22  106\n",
      "\n",
      "\n",
      "frac = 0.07\n",
      "re shape\n",
      "0    0.610937\n",
      "1    0.389063\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       195\n",
      "           1       0.79      0.77      0.78       124\n",
      "\n",
      "    accuracy                           0.83       319\n",
      "   macro avg       0.83      0.82      0.82       319\n",
      "weighted avg       0.83      0.83      0.83       319\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           170  25\n",
      "1            28  96\n",
      "\n",
      "\n",
      "frac = 0.08\n",
      "re shape\n",
      "0    0.64199\n",
      "1    0.35801\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       218\n",
      "           1       0.79      0.77      0.78       128\n",
      "\n",
      "    accuracy                           0.84       346\n",
      "   macro avg       0.83      0.82      0.83       346\n",
      "weighted avg       0.84      0.84      0.84       346\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           191  27\n",
      "1            29  99\n",
      "\n",
      "\n",
      "frac = 0.09\n",
      "re shape\n",
      "0    0.66863\n",
      "1    0.33137\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       239\n",
      "           1       0.79      0.74      0.76       135\n",
      "\n",
      "    accuracy                           0.83       374\n",
      "   macro avg       0.82      0.81      0.82       374\n",
      "weighted avg       0.83      0.83      0.83       374\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           212   27\n",
      "1            35  100\n",
      "\n",
      "\n",
      "frac = 0.1\n",
      "re shape\n",
      "0    0.691579\n",
      "1    0.308421\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       264\n",
      "           1       0.77      0.73      0.75       138\n",
      "\n",
      "    accuracy                           0.83       402\n",
      "   macro avg       0.82      0.81      0.81       402\n",
      "weighted avg       0.83      0.83      0.83       402\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           234   30\n",
      "1            37  101\n",
      "\n",
      "\n",
      "frac = 0.11\n",
      "re shape\n",
      "0    0.711556\n",
      "1    0.288444\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       293\n",
      "           1       0.74      0.74      0.74       137\n",
      "\n",
      "    accuracy                           0.84       430\n",
      "   macro avg       0.81      0.81      0.81       430\n",
      "weighted avg       0.84      0.84      0.84       430\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           258   35\n",
      "1            35  102\n",
      "\n",
      "\n",
      "frac = 0.12\n",
      "re shape\n",
      "0    0.729103\n",
      "1    0.270897\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89       322\n",
      "           1       0.74      0.76      0.75       135\n",
      "\n",
      "    accuracy                           0.85       457\n",
      "   macro avg       0.82      0.82      0.82       457\n",
      "weighted avg       0.85      0.85      0.85       457\n",
      "\n",
      "col_0         0    1\n",
      "fraudulent          \n",
      "0           287   35\n",
      "1            33  102\n",
      "\n",
      "\n",
      "frac = 0.13\n",
      "re shape\n",
      "0    0.744637\n",
      "1    0.255363\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90       361\n",
      "           1       0.70      0.72      0.71       124\n",
      "\n",
      "    accuracy                           0.85       485\n",
      "   macro avg       0.80      0.80      0.80       485\n",
      "weighted avg       0.85      0.85      0.85       485\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           322  39\n",
      "1            35  89\n",
      "\n",
      "\n",
      "frac = 0.14\n",
      "re shape\n",
      "0    0.758392\n",
      "1    0.241608\n",
      "Name: fraudulent, dtype: float64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       396\n",
      "           1       0.69      0.72      0.70       117\n",
      "\n",
      "    accuracy                           0.86       513\n",
      "   macro avg       0.80      0.81      0.81       513\n",
      "weighted avg       0.86      0.86      0.86       513\n",
      "\n",
      "col_0         0   1\n",
      "fraudulent         \n",
      "0           358  38\n",
      "1            33  84\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\", sep = \";\")\n",
    "\n",
    "df['description'] = df['description'].apply(lambda x : clean_data(x))\n",
    "df = cleandataset(df)\n",
    "\n",
    "# check class distribution/\n",
    "print(df['fraudulent'].value_counts(normalize = True))\n",
    "\n",
    "df_fraud = df[df.fraudulent == 1]\n",
    "df_true = df[df.fraudulent == 0]\n",
    "\n",
    "frac = [x * 0.01 for x in range(6, 15)]\n",
    "models = [trainer(df, KNeighborsClassifier(n_neighbors=2), df_fraud, df_true, step) for step in frac]\n",
    "\n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5d7f9",
   "metadata": {},
   "source": [
    "## Ensemble classifier\n",
    "\n",
    "Too long to train, then to test tuning. Maybe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2c7e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification - necessary dependencies\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e23f7dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833946895165556\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/2262740463.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassification_report\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_y\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;31m# confusion matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcrosstab\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36mclassification_report\u001B[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001B[0m\n\u001B[0;32m   1968\u001B[0m     \"\"\"\n\u001B[0;32m   1969\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1970\u001B[1;33m     \u001B[0my_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1971\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1972\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001B[0m in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_type\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001B[0m\u001B[0;32m     93\u001B[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)\n",
    "results = model_selection.cross_val_score(model, train_data, train_y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "870b286d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This BaggingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16360/2800885720.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# print(model.score(test_data, test_y))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"MSE : \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_y\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m**\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    675\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0mpredicted\u001B[0m \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    676\u001B[0m         \"\"\"\n\u001B[1;32m--> 677\u001B[1;33m         \u001B[0mpredicted_probabilitiy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    678\u001B[0m         return self.classes_.take((np.argmax(predicted_probabilitiy, axis=1)),\n\u001B[0;32m    679\u001B[0m                                   axis=0)\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    701\u001B[0m             \u001B[0mclasses\u001B[0m \u001B[0mcorresponds\u001B[0m \u001B[0mto\u001B[0m \u001B[0mthat\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mattribute\u001B[0m \u001B[1;33m:\u001B[0m\u001B[0mterm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mclasses_\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    702\u001B[0m         \"\"\"\n\u001B[1;32m--> 703\u001B[1;33m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    704\u001B[0m         \u001B[1;31m# Check data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    705\u001B[0m         X = check_array(\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1096\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1097\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mattrs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1098\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'name'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1099\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This BaggingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"score train\")\n",
    "print(model.score(train_data, train_y))\n",
    "print(\"score test\")\n",
    "print(model.score(test_data, test_y))\n",
    "\n",
    "print(\"MSE : \", np.sqrt(((test_y - model.predict(test_data)) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classification\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "num_trees = 70\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "print(classification_report(test_y , predictions))\n",
    "# confusion matrix\n",
    "pd.crosstab(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble for Classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "print(classification_report(test_y , predictions))\n",
    "# confusion matrix\n",
    "pd.crosstab(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f890b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8b628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef5c5d7",
   "metadata": {},
   "source": [
    "## xgboost\n",
    "\n",
    "Too long to train. Must write a f1-score + recall score + confusion matrix... First results are very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ee156c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train\n",
      "0.9791990093389004\n",
      "score test\n",
      "0.4548039952330938\n",
      "MSE :  0.3679619445889928\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clf = xgb.XGBRegressor(random_state=0)\n",
    "\n",
    "# clf = xgb.XGBRegressor(random_state=0, n_jobs=6, max_depth=8, grow_policy='lossguide', max_leaves=100,\n",
    "#                              max_bin=64, reg_alpha=0, reg_lambda=0, n_estimators=100, learning_rate=0.1,\n",
    "#                              tree_method='auto')\n",
    "\n",
    "clf.fit(train_data, train_y)\n",
    "\n",
    "print(\"score train\")\n",
    "print(clf.score(train_data, train_y))\n",
    "print(\"score test\")\n",
    "print(clf.score(test_data, test_y))\n",
    "\n",
    "print(\"MSE : \", np.sqrt(((test_y - clf.predict(test_data)) ** 2).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49594be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# cm = confusion_matrix(test_y, predictions)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a3151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
